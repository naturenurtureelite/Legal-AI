import string
import sys
import os
from rouge_score import rouge_scorer

scorer = rouge_scorer.RougeScorer(['rouge2','rouge1', 'rougeL'], use_stemmer=True)
#variable initialization
import spacy
nlp = spacy.load("en_core_web_sm")
avg_length=[1700, 1822, 1230, 1190, 1771, 1470, 1423, 3565, 1817, 1666, 1903, 1960, 2884, 1477, 1984, 1964, 2180, 1401, 4610, 1742, 2155, 1298, 1734, 1856, 1300, 1164, 1406, 1487, 1151, 5392, 1270, 1258, 1419, 1254, 1176, 1518, 1332, 2011, 1950, 1430, 1697, 979, 2130, 1568, 2224, 1439, 2322, 1608, 1498, 1030]
#avg_length=[1588,1034,1490,5705,1594,1669,1182,1631,2157,2179,2578,1906,1592,1172,1988,1731,1726,1678,1761,2246,1562,1814,1534,2044,1701,1350,3278,1413,1840,2428,1238,1399,1508,2030,934,1339,1792,2200,1389,1967,2766,2090,1492,2392,1425,1676,1420,1396,1566,1783]
uu=0
v4=[]
v5=[]
v6=[]
v7=[]
count=0
countf=0
counta=0
countr=0
countp=0
countr1=0
countr2=0
counti=0
counts=0
first=0
last=0
first1=0
last1=0
k1=0.0
k2=0.0
k3=0.0
k4=0.0
k5=0.0
k6=0.0
k7=0.0
k8=0.0
first1=0.0
last1=0.0
first2=0.0
last2=0.0
#a=["ChineseGist"]
if sys.argv[1]=="unsupervised_domain_independent":
	a=["LexRankSummarizer","LuhnSummarizer","LsaSummarizer","ReductionSummarizer","DSDR"]
elif sys.argv[1]=="unsupervised_domain_specific":
	a=["LetSum","KMM","CaseSummarizer","MMR","DELSumm"]
elif sys.argv[1]=="supervised":
	a=["Summarunner_AttnRNN","Summarunner_RNN_RNN","Summarunner_CNN_RNN","gist","BERT1"]
elif sys.argv[1]=="unsupervised":
	a=["LexRankSummarizer","LuhnSummarizer","LsaSummarizer","ReductionSummarizer","DSDR","LetSum","KMM","CaseSummarizer","MMR","DELSumm"]
elif sys.argv[1]=="all_methods":
	a=["BERT","CaseSummarizer","gist","DELSumm","DSDR","KMM","LetSum","LexRankSummarizer","LsaSummarizer","LuhnSummarizer","MMR","ReductionSummarizer","Summarunner_AttnRNN","Summarunner_RNN_RNN","Summarunner_CNN_RNN"]
elif sys.argv[1]=="top_4":
	a=["Summarunner_RNN_RNN","Summarunner_AttnRNN","BERT","DELSumm"]

#a=["LetSum","KMM","CaseSummarizer","MMR","DELSumm"]
#list of all possible summarization algorithms
#a=["BERT","CaseSummarizer","DELSumm","DSDR","KMM","LetSum","LexRankSummarizer","LsaSummarizer","LuhnSummarizer","MMR","ReductionSummarizer","Summarunner_AttnRNN","Summarunner_CNN_RNN","Summarunner_RNN_RNN","gist"]
#a=["LexRankSummarizer","LuhnSummarizer","LsaSummarizer","ReductionSummarizer","LuhnSummarizer"]
#a=["LetSum","KMM","CaseSummarizer","MMR","DELSumm"]
#a=["LexRankSummarizer","LsaSummarizer","LuhnSummarizer","ReductionSummarizer","DSDR"]
t=os.listdir("Full-Text-segments/India/")
print(t)
#loop over all summarization algorithms
def sortSecond(val):
    return val[1] 

for i in range(0,50):
	v1=[]
	v4=[]
	v5=[]
	v7=[]
	pair=[]
		#loop over all 50 files
	file1 = open("Full-Text-segments/India/"+t[i], 'r')
	Lines = file1.readlines()
 
	#count = 0
			
			#read a line from a file in the full text segments
	for line in Lines:
		p=line.strip()
		if p[-1]==".":
			v1.append(p[:-1])
		else:
			v1.append(p)
			


			#separate a line into sentence and label
	for l in range(0,len(v1)):
		u=v1[l]
		u=u.split("-->")
		u[0]=u[0].strip()
		if u[0][-1]==".":
			v4.append(u[0][:-1])
		else:
			v4.append(u[0])
				
		v5.append(u[1])
			#v4 contains sentence
			#v5 contains label
	'''
	for x2 in range(0,len(v4)):
		a_string=v4[x2]
		alphanumeric=""
		for character in a_string:
			if character.isalnum():
				alphanumeric+=character
		v7.append(alphanumeric)
	'''
	v7=v4
	count=[]
	for j in range(0,len(v7)):
		count.append(0)
	
	for j in range(0,len(a)):
			count_borda=1
			#open a particular file and read
			file1 = open("extractive/"+a[j]+'/'+t[i], 'r')
			Lines = file1.readlines()

			v=[]
			v6=[]
			#v1=[]
			#p=""
			#count = 0

			# read a line from a summarized document where the summarized text is generated by a algorithm 
			for line in Lines:
				p=line.strip()
				if p[-1]==".":
					v.append(p[:-1])
				else:
					v.append(p)
			

			#read a line from a file in the full text segments		
			
			
			
			#remove the punctuation characters and only store only alphanumeric characters
			'''
			for x1 in range(0,len(v)):
				a_string=v[x1]
				alphanumeric=""
				for character in a_string:
					if character.isalnum():
						alphanumeric+=character
				v6.append(alphanumeric)
			'''
			#remove the punctuation characters and only store only alphanumeric characters
			v6=v	
			maxi=-1.0
			#check whether the line present in the summary file is present in the first half or the second half of the text file
			for x1 in range(0,len(v6)):
				for x2 in range(0,len(v7)):
					#print(v6[x2],v7[x1])
					scores1=scorer.score(v6[x1],v7[x2])
					if scores1['rouge2'][2]>maxi:
						maxi=scores1['rouge2'][2]
						pos=x2

					#if v6[x1]==v7[x2]:
				#print(pos)
				maxi=-1.0
				count[pos]=count[pos]+count_borda
				count_borda=count_borda+1

	#for m in range(0,len(count)):
	#	print(count[m])	

	for m in range(0,len(count)):		
		pair.append([v4[m],((count[m]*1.000000)/15.000000)])	
	pair.sort(key = sortSecond,reverse=False)
	#print(pair)
	no_of_words=0
	file5 = open("unordered/"+str(t[i]), 'a+')

	for l in range(0,len(pair)):
		pair[l][0]=pair[l][0].translate(str.maketrans('', '', string.punctuation))  # remove punctuation from a line
		parsed = nlp(pair[l][0])
		no_of_words =no_of_words+len(parsed)
		if no_of_words<=avg_length[i]:
			file5.write(pair[l][0]+"."+"\n")
		else:
			no_of_words=no_of_words-len(parsed)
			break
	#total_length=total_length+no_of_words
	#print(total_length)
	#print(no_of_words)
	#print(avg_length[i])
	#print(leng)
	#pair=[]
	#print(t[i])
	
	#for m in range(0,int(leng)):
		
	pair=[]
	#for i in range(0,len(pair)):
	#	print(pair[0],"---->",pair[1])
	#pair=[] 	
	#print("---------------------------")